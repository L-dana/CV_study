import numpy as np

'''
신경망 학습 시 학습이 얼마나 잘 되는지 나타낸 척도가 필요. 이 척도로 "손실" 을 사용

손실 => 신경망이 예측한 결과와 실제 정답을 비교해서 예측이 얼마나 나쁜지 산출한 단일값(스칼라).

신경망의 손실은 손실 함수(Loss Function)로 구함, 다중 클래스 분류 신경망에서는 일반적으로 
교차 엔트로피 오차(Cross Entropy Error) 손실함수를 사용

소프트맥스 함수로 신경망의 출력이 확률 형태로 출력됨, 소프트맥스 함수를 직관적으로 요약하면 다음과 같음
x 번째 출력 / 출력의 합

소프트맥스 함수의 출력은 0 ~ 1 사이의 값이며, 모든 값을 더하면 1이 됨.

소프트맥스의 출력인 확률은 다음 차례인 교차 엔트로피 오차에 입력됨으로써 예측 결과와 정답의 차이를 수치로 도출함, 도출된 수치가 손실값.




학습 시 신경망은 학습 데이터 -> 손실 출력 을 시행
이때 각 매개변수의 변화 정도에 따른 손실값 변화량(매개변수에 대한 손실의 기울기)을 구한다면 매개변수를 갱신함으로써 학습이 진행됨.

신경망의 기울기는 "오차역전파법(Back-Propergation)" 으로 구할 수 있음




'''
